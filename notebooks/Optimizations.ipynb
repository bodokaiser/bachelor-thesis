{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>voltage</th>\n",
       "      <th>amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015000</td>\n",
       "      <td>0.644351</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.014999</td>\n",
       "      <td>0.577405</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.014998</td>\n",
       "      <td>0.711297</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014998</td>\n",
       "      <td>0.644351</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.014997</td>\n",
       "      <td>0.711297</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time   voltage  amplitude\n",
       "0 -0.015000  0.644351        0.3\n",
       "1 -0.014999  0.577405        0.3\n",
       "2 -0.014998  0.711297        0.3\n",
       "3 -0.014998  0.644351        0.3\n",
       "4 -0.014997  0.711297        0.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf('data4.hdf', 'table')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1024\n",
    "\n",
    "a, b = (23287, 54485)\n",
    "\n",
    "t0 = df[df['amplitude'] == .3]['time'][a]\n",
    "t1 = df[df['amplitude'] == .3]['time'][b]\n",
    "df = df[(df['time'] > t0) & ((df['time'] < t1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, f1 = (90e6, 110e6)\n",
    "\n",
    "def time_to_freq(t):\n",
    "    return f0 + (f1 - f0) * (t - t0) / (t1 - t0)\n",
    "\n",
    "def downscale(x, N):\n",
    "    i = np.linspace(0, 1, len(x))\n",
    "    j = np.linspace(0, 1, N)\n",
    "\n",
    "    return np.interp(j, i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin1 = nn.Linear(num_features, num_hidden)\n",
    "        self.lin2 = nn.Linear(num_hidden, num_outputs)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.lin2.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "net = Net(2, 64, 1).double()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7866105856"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = df[df['amplitude'] == df['amplitude'].max()]['voltage'].min()\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 716800), (716800,))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = []\n",
    "amplitudes = []\n",
    "voltages = []\n",
    "\n",
    "for A in df['amplitude'].unique():\n",
    "    s = df['amplitude'] == A\n",
    "    \n",
    "    f = downscale(time_to_freq(df[s]['time']), N)\n",
    "    u = downscale(df[s]['voltage'], N)\n",
    "    \n",
    "    frequencies.append(f)\n",
    "    voltages.append(u)\n",
    "    amplitudes.append(A*np.ones(N))\n",
    "    \n",
    "inputs = np.stack([\n",
    "    np.array(frequencies).flatten(),\n",
    "    np.array(voltages).flatten()\n",
    "])\n",
    "\n",
    "targets = np.array(amplitudes).flatten()\n",
    "\n",
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = TensorDataset(torch.from_numpy(inputs).t(), torch.from_numpy(targets).unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 0, loss: 0.04211641855342204\n",
      "epoch: 0, iteration: 10000, loss: 0.036178568323850545\n",
      "epoch: 0, iteration: 20000, loss: 0.04209824055164772\n",
      "epoch: 0, iteration: 30000, loss: 0.044495493399918644\n",
      "epoch: 0, iteration: 40000, loss: 0.03491926767755383\n",
      "epoch: 0, iteration: 50000, loss: 0.0686844024798204\n",
      "epoch: 0, iteration: 60000, loss: 0.03946907564699595\n",
      "epoch: 0, iteration: 70000, loss: 0.05996274145865982\n",
      "epoch: 1, iteration: 0, loss: 0.039151614669733145\n",
      "epoch: 1, iteration: 10000, loss: 0.05900398183138651\n",
      "epoch: 1, iteration: 20000, loss: 0.06024578629697393\n",
      "epoch: 1, iteration: 30000, loss: 0.045469960672572994\n",
      "epoch: 1, iteration: 40000, loss: 0.028724395240839713\n",
      "epoch: 1, iteration: 50000, loss: 0.025964710871499326\n",
      "epoch: 1, iteration: 60000, loss: 0.05065959929722678\n",
      "epoch: 1, iteration: 70000, loss: 0.04772603486933481\n",
      "epoch: 2, iteration: 0, loss: 0.058074384743321404\n",
      "epoch: 2, iteration: 10000, loss: 0.047027338608539464\n",
      "epoch: 2, iteration: 20000, loss: 0.04624900087369245\n",
      "epoch: 2, iteration: 30000, loss: 0.03955870311484652\n",
      "epoch: 2, iteration: 40000, loss: 0.04084096411932609\n",
      "epoch: 2, iteration: 50000, loss: 0.04649403081340682\n",
      "epoch: 2, iteration: 60000, loss: 0.031892513398228454\n",
      "epoch: 2, iteration: 70000, loss: 0.06411534007815653\n",
      "epoch: 3, iteration: 0, loss: 0.0627558269857851\n",
      "epoch: 3, iteration: 10000, loss: 0.045120344625247374\n",
      "epoch: 3, iteration: 20000, loss: 0.026176771309518183\n",
      "epoch: 3, iteration: 30000, loss: 0.11089424347911765\n",
      "epoch: 3, iteration: 40000, loss: 0.026213749371757335\n",
      "epoch: 3, iteration: 50000, loss: 0.04010385783236298\n",
      "epoch: 3, iteration: 60000, loss: 0.04485062785947413\n",
      "epoch: 3, iteration: 70000, loss: 0.04811823816777179\n",
      "epoch: 4, iteration: 0, loss: 0.031147835780568532\n",
      "epoch: 4, iteration: 10000, loss: 0.014026504570575957\n",
      "epoch: 4, iteration: 20000, loss: 0.030466105889503214\n",
      "epoch: 4, iteration: 30000, loss: 0.051653254375758885\n",
      "epoch: 4, iteration: 40000, loss: 0.05503063238599114\n",
      "epoch: 4, iteration: 50000, loss: 0.03275909553932794\n",
      "epoch: 4, iteration: 60000, loss: 0.03244058930692333\n",
      "epoch: 4, iteration: 70000, loss: 0.032499159714247536\n",
      "epoch: 5, iteration: 0, loss: 0.0433290744545075\n",
      "epoch: 5, iteration: 10000, loss: 0.04763787728759\n",
      "epoch: 5, iteration: 20000, loss: 0.062266118673441576\n",
      "epoch: 5, iteration: 30000, loss: 0.05292044073701809\n",
      "epoch: 5, iteration: 40000, loss: 0.10074828918452276\n",
      "epoch: 5, iteration: 50000, loss: 0.030035892617800007\n",
      "epoch: 5, iteration: 60000, loss: 0.06505420994969294\n",
      "epoch: 5, iteration: 70000, loss: 0.033925598903030714\n",
      "epoch: 6, iteration: 0, loss: 0.06920892935444316\n",
      "epoch: 6, iteration: 10000, loss: 0.025669640049975045\n",
      "epoch: 6, iteration: 20000, loss: 0.03319651866048206\n",
      "epoch: 6, iteration: 30000, loss: 0.02837364743668915\n",
      "epoch: 6, iteration: 40000, loss: 0.034444543972981155\n",
      "epoch: 6, iteration: 50000, loss: 0.01604032569192289\n",
      "epoch: 6, iteration: 60000, loss: 0.0432679877127629\n",
      "epoch: 6, iteration: 70000, loss: 0.027737966923311506\n",
      "epoch: 7, iteration: 0, loss: 0.05330707193208552\n",
      "epoch: 7, iteration: 10000, loss: 0.043450905844930755\n",
      "epoch: 7, iteration: 20000, loss: 0.04067837896072608\n",
      "epoch: 7, iteration: 30000, loss: 0.05669290640772372\n",
      "epoch: 7, iteration: 40000, loss: 0.037646042544147815\n",
      "epoch: 7, iteration: 50000, loss: 0.024822903471910424\n",
      "epoch: 7, iteration: 60000, loss: 0.06550207529840742\n",
      "epoch: 7, iteration: 70000, loss: 0.045634296216806494\n",
      "epoch: 8, iteration: 0, loss: 0.0493311047990148\n",
      "epoch: 8, iteration: 10000, loss: 0.03125034838644491\n",
      "epoch: 8, iteration: 20000, loss: 0.041672747225545245\n",
      "epoch: 8, iteration: 30000, loss: 0.03584964629650187\n",
      "epoch: 8, iteration: 40000, loss: 0.033901564039506685\n",
      "epoch: 8, iteration: 50000, loss: 0.04981342619532813\n",
      "epoch: 8, iteration: 60000, loss: 0.027344821209462987\n",
      "epoch: 8, iteration: 70000, loss: 0.049520834240105574\n",
      "epoch: 9, iteration: 0, loss: 0.029011990170105657\n",
      "epoch: 9, iteration: 10000, loss: 0.053328142616868926\n",
      "epoch: 9, iteration: 20000, loss: 0.05195770668221607\n",
      "epoch: 9, iteration: 30000, loss: 0.0433635597116823\n",
      "epoch: 9, iteration: 40000, loss: 0.03538417387464716\n",
      "epoch: 9, iteration: 50000, loss: 0.06146848524239892\n",
      "epoch: 9, iteration: 60000, loss: 0.030275662032435313\n",
      "epoch: 9, iteration: 70000, loss: 0.0502953937713058\n",
      "epoch: 10, iteration: 0, loss: 0.043862879083594174\n",
      "epoch: 10, iteration: 10000, loss: 0.04107337958771538\n",
      "epoch: 10, iteration: 20000, loss: 0.036014365849555696\n",
      "epoch: 10, iteration: 30000, loss: 0.05037404989451694\n",
      "epoch: 10, iteration: 40000, loss: 0.039546807976308836\n",
      "epoch: 10, iteration: 50000, loss: 0.024978633386974102\n",
      "epoch: 10, iteration: 60000, loss: 0.044004979874919956\n",
      "epoch: 10, iteration: 70000, loss: 0.060498864279184814\n",
      "epoch: 11, iteration: 0, loss: 0.03988220566211387\n",
      "epoch: 11, iteration: 10000, loss: 0.07444984346323255\n",
      "epoch: 11, iteration: 20000, loss: 0.09187305282188377\n",
      "epoch: 11, iteration: 30000, loss: 0.031067763368558644\n",
      "epoch: 11, iteration: 40000, loss: 0.03416631748854244\n",
      "epoch: 11, iteration: 50000, loss: 0.0739557503404818\n",
      "epoch: 11, iteration: 60000, loss: 0.051610492455130365\n",
      "epoch: 11, iteration: 70000, loss: 0.04390654257624317\n",
      "epoch: 12, iteration: 0, loss: 0.036843598401362046\n",
      "epoch: 12, iteration: 10000, loss: 0.04460797267588312\n",
      "epoch: 12, iteration: 20000, loss: 0.037730332423168284\n",
      "epoch: 12, iteration: 30000, loss: 0.05166624528878157\n",
      "epoch: 12, iteration: 40000, loss: 0.024601631287163035\n",
      "epoch: 12, iteration: 50000, loss: 0.033600822685509915\n",
      "epoch: 12, iteration: 60000, loss: 0.0481115025848905\n",
      "epoch: 12, iteration: 70000, loss: 0.08111601335467125\n",
      "epoch: 13, iteration: 0, loss: 0.029694566247177746\n",
      "epoch: 13, iteration: 10000, loss: 0.030258368891373327\n",
      "epoch: 13, iteration: 20000, loss: 0.02622383787766818\n",
      "epoch: 13, iteration: 30000, loss: 0.06636066989167205\n",
      "epoch: 13, iteration: 40000, loss: 0.05398859954460065\n",
      "epoch: 13, iteration: 50000, loss: 0.036259987741217393\n",
      "epoch: 13, iteration: 60000, loss: 0.0401415151806145\n",
      "epoch: 13, iteration: 70000, loss: 0.04233386770673793\n",
      "epoch: 14, iteration: 0, loss: 0.038560365599106146\n",
      "epoch: 14, iteration: 10000, loss: 0.040879650043396075\n",
      "epoch: 14, iteration: 20000, loss: 0.04486699631712346\n",
      "epoch: 14, iteration: 30000, loss: 0.041811312890855885\n",
      "epoch: 14, iteration: 40000, loss: 0.046054506276718074\n",
      "epoch: 14, iteration: 50000, loss: 0.031083804976380518\n",
      "epoch: 14, iteration: 60000, loss: 0.018421676931809357\n",
      "epoch: 14, iteration: 70000, loss: 0.03188801813077174\n",
      "epoch: 15, iteration: 0, loss: 0.04433613677912253\n",
      "epoch: 15, iteration: 10000, loss: 0.04534059116109186\n",
      "epoch: 15, iteration: 20000, loss: 0.054638630908835396\n",
      "epoch: 15, iteration: 30000, loss: 0.07374136746736318\n",
      "epoch: 15, iteration: 40000, loss: 0.0566973725493604\n",
      "epoch: 15, iteration: 50000, loss: 0.021776275420150114\n",
      "epoch: 15, iteration: 60000, loss: 0.03849598379584491\n",
      "epoch: 15, iteration: 70000, loss: 0.03581307374976866\n",
      "epoch: 16, iteration: 0, loss: 0.03735853728184761\n",
      "epoch: 16, iteration: 10000, loss: 0.06890033093755368\n",
      "epoch: 16, iteration: 20000, loss: 0.04395762263571435\n",
      "epoch: 16, iteration: 30000, loss: 0.0527400719369545\n",
      "epoch: 16, iteration: 40000, loss: 0.0400839628363031\n",
      "epoch: 16, iteration: 50000, loss: 0.037684377564129096\n",
      "epoch: 16, iteration: 60000, loss: 0.09214525494748235\n",
      "epoch: 16, iteration: 70000, loss: 0.06026504348004361\n",
      "epoch: 17, iteration: 0, loss: 0.038541094038172546\n",
      "epoch: 17, iteration: 10000, loss: 0.07005723655615666\n",
      "epoch: 17, iteration: 20000, loss: 0.04681790128794838\n",
      "epoch: 17, iteration: 30000, loss: 0.020839701641539574\n",
      "epoch: 17, iteration: 40000, loss: 0.054898815469535636\n",
      "epoch: 17, iteration: 50000, loss: 0.04891433644035542\n",
      "epoch: 17, iteration: 60000, loss: 0.05308381756071612\n",
      "epoch: 17, iteration: 70000, loss: 0.03080070597138551\n",
      "epoch: 18, iteration: 0, loss: 0.0407761818594448\n",
      "epoch: 18, iteration: 10000, loss: 0.06555438311841907\n",
      "epoch: 18, iteration: 20000, loss: 0.030592361720295523\n",
      "epoch: 18, iteration: 30000, loss: 0.044451785389070186\n",
      "epoch: 18, iteration: 40000, loss: 0.04262813489268717\n",
      "epoch: 18, iteration: 50000, loss: 0.021310649563755595\n",
      "epoch: 18, iteration: 60000, loss: 0.07244793702108467\n",
      "epoch: 18, iteration: 70000, loss: 0.05833753083435121\n",
      "epoch: 19, iteration: 0, loss: 0.02533456773343213\n",
      "epoch: 19, iteration: 10000, loss: 0.05033973950974768\n",
      "epoch: 19, iteration: 20000, loss: 0.042380424981484914\n",
      "epoch: 19, iteration: 30000, loss: 0.034752159488169676\n",
      "epoch: 19, iteration: 40000, loss: 0.04911673787361562\n",
      "epoch: 19, iteration: 50000, loss: 0.0319667467643569\n",
      "epoch: 19, iteration: 60000, loss: 0.05470285976170869\n",
      "epoch: 19, iteration: 70000, loss: 0.02698037011727636\n",
      "epoch: 20, iteration: 0, loss: 0.09195678306889377\n",
      "epoch: 20, iteration: 10000, loss: 0.04962362696115178\n",
      "epoch: 20, iteration: 20000, loss: 0.030765023962386027\n",
      "epoch: 20, iteration: 30000, loss: 0.043977218017682285\n",
      "epoch: 20, iteration: 40000, loss: 0.06177040094277405\n",
      "epoch: 20, iteration: 50000, loss: 0.059017334404088725\n",
      "epoch: 20, iteration: 60000, loss: 0.0696436848981147\n",
      "epoch: 20, iteration: 70000, loss: 0.03230695111692944\n",
      "epoch: 21, iteration: 0, loss: 0.04423762539559282\n",
      "epoch: 21, iteration: 10000, loss: 0.0725853200057023\n",
      "epoch: 21, iteration: 20000, loss: 0.05102542987424748\n",
      "epoch: 21, iteration: 30000, loss: 0.039071978420284266\n",
      "epoch: 21, iteration: 40000, loss: 0.05345659385763215\n",
      "epoch: 21, iteration: 50000, loss: 0.053595794615589984\n",
      "epoch: 21, iteration: 60000, loss: 0.053678521043614216\n",
      "epoch: 21, iteration: 70000, loss: 0.05308172488638581\n",
      "epoch: 22, iteration: 0, loss: 0.055709057283346644\n",
      "epoch: 22, iteration: 10000, loss: 0.05929672749175404\n",
      "epoch: 22, iteration: 20000, loss: 0.0333716309656543\n",
      "epoch: 22, iteration: 30000, loss: 0.039596227738100606\n",
      "epoch: 22, iteration: 40000, loss: 0.039121169157626756\n",
      "epoch: 22, iteration: 50000, loss: 0.04122729696196397\n",
      "epoch: 22, iteration: 60000, loss: 0.05706545743737388\n",
      "epoch: 22, iteration: 70000, loss: 0.028933512591047917\n",
      "epoch: 23, iteration: 0, loss: 0.06651657267007485\n",
      "epoch: 23, iteration: 10000, loss: 0.07710912834811076\n",
      "epoch: 23, iteration: 20000, loss: 0.024010723944601176\n",
      "epoch: 23, iteration: 30000, loss: 0.053488376420172214\n",
      "epoch: 23, iteration: 40000, loss: 0.05324101650783606\n",
      "epoch: 23, iteration: 50000, loss: 0.030483831529187967\n",
      "epoch: 23, iteration: 60000, loss: 0.054862372801851314\n",
      "epoch: 23, iteration: 70000, loss: 0.031145143447295964\n",
      "epoch: 24, iteration: 0, loss: 0.045427748065741666\n",
      "epoch: 24, iteration: 10000, loss: 0.058115262581379626\n",
      "epoch: 24, iteration: 20000, loss: 0.03725092723442654\n",
      "epoch: 24, iteration: 30000, loss: 0.0229800568043863\n",
      "epoch: 24, iteration: 40000, loss: 0.032501070628202754\n",
      "epoch: 24, iteration: 50000, loss: 0.031080923445388108\n",
      "epoch: 24, iteration: 60000, loss: 0.07330442465703356\n",
      "epoch: 24, iteration: 70000, loss: 0.04565286950070853\n",
      "epoch: 25, iteration: 0, loss: 0.030235880603697966\n",
      "epoch: 25, iteration: 10000, loss: 0.08813028355730548\n",
      "epoch: 25, iteration: 20000, loss: 0.049336406986254036\n",
      "epoch: 25, iteration: 30000, loss: 0.024276348133478003\n",
      "epoch: 25, iteration: 40000, loss: 0.023936541547294802\n",
      "epoch: 25, iteration: 50000, loss: 0.03288919910185391\n",
      "epoch: 25, iteration: 60000, loss: 0.04042916754143068\n",
      "epoch: 25, iteration: 70000, loss: 0.05028464097827644\n",
      "epoch: 26, iteration: 0, loss: 0.09490156246696183\n",
      "epoch: 26, iteration: 10000, loss: 0.04396203594998017\n",
      "epoch: 26, iteration: 20000, loss: 0.06447065929749729\n",
      "epoch: 26, iteration: 30000, loss: 0.03944095603798899\n",
      "epoch: 26, iteration: 40000, loss: 0.02507133304731831\n",
      "epoch: 26, iteration: 50000, loss: 0.05140587150861007\n",
      "epoch: 26, iteration: 60000, loss: 0.02068217488412344\n",
      "epoch: 26, iteration: 70000, loss: 0.05733187778695842\n",
      "epoch: 27, iteration: 0, loss: 0.04485266112992866\n",
      "epoch: 27, iteration: 10000, loss: 0.03605149835915625\n",
      "epoch: 27, iteration: 20000, loss: 0.0337658458687682\n",
      "epoch: 27, iteration: 30000, loss: 0.036973240074212155\n",
      "epoch: 27, iteration: 40000, loss: 0.032480453445841224\n",
      "epoch: 27, iteration: 50000, loss: 0.028856508228918932\n",
      "epoch: 27, iteration: 60000, loss: 0.064555602182118\n",
      "epoch: 27, iteration: 70000, loss: 0.04727501019480611\n",
      "epoch: 28, iteration: 0, loss: 0.031701620623999435\n",
      "epoch: 28, iteration: 10000, loss: 0.055569003883319534\n",
      "epoch: 28, iteration: 20000, loss: 0.04102358182356451\n",
      "epoch: 28, iteration: 30000, loss: 0.06931993297889272\n",
      "epoch: 28, iteration: 40000, loss: 0.028689346188876023\n",
      "epoch: 28, iteration: 50000, loss: 0.05295607641375964\n",
      "epoch: 28, iteration: 60000, loss: 0.036232502950038006\n",
      "epoch: 28, iteration: 70000, loss: 0.016507686429161977\n",
      "epoch: 29, iteration: 0, loss: 0.06392062877004666\n",
      "epoch: 29, iteration: 10000, loss: 0.012175977395497271\n",
      "epoch: 29, iteration: 20000, loss: 0.048564900959057\n",
      "epoch: 29, iteration: 30000, loss: 0.03761673656224096\n",
      "epoch: 29, iteration: 40000, loss: 0.030574140729038784\n",
      "epoch: 29, iteration: 50000, loss: 0.05961732757181572\n",
      "epoch: 29, iteration: 60000, loss: 0.06392549463204565\n",
      "epoch: 29, iteration: 70000, loss: 0.048608699053029954\n",
      "epoch: 30, iteration: 0, loss: 0.03047347536149323\n",
      "epoch: 30, iteration: 10000, loss: 0.027998003278599776\n",
      "epoch: 30, iteration: 20000, loss: 0.014342205665089688\n",
      "epoch: 30, iteration: 30000, loss: 0.04531691817345361\n",
      "epoch: 30, iteration: 40000, loss: 0.044255687448872524\n",
      "epoch: 30, iteration: 50000, loss: 0.0433901111782942\n",
      "epoch: 30, iteration: 60000, loss: 0.014697363995215354\n",
      "epoch: 30, iteration: 70000, loss: 0.05939951610132026\n",
      "epoch: 31, iteration: 0, loss: 0.028773382363281204\n",
      "epoch: 31, iteration: 10000, loss: 0.05064059583328708\n",
      "epoch: 31, iteration: 20000, loss: 0.04139940608058096\n",
      "epoch: 31, iteration: 30000, loss: 0.040933734500256\n",
      "epoch: 31, iteration: 40000, loss: 0.044340655296382404\n",
      "epoch: 31, iteration: 50000, loss: 0.038692297589569505\n",
      "epoch: 31, iteration: 60000, loss: 0.03383445397213446\n",
      "epoch: 31, iteration: 70000, loss: 0.05177591482848376\n",
      "epoch: 32, iteration: 0, loss: 0.03550008919285258\n",
      "epoch: 32, iteration: 10000, loss: 0.05723360828006245\n",
      "epoch: 32, iteration: 20000, loss: 0.05727506713388003\n",
      "epoch: 32, iteration: 30000, loss: 0.05887162267127575\n",
      "epoch: 32, iteration: 40000, loss: 0.04278225688301347\n",
      "epoch: 32, iteration: 50000, loss: 0.058919174952832346\n",
      "epoch: 32, iteration: 60000, loss: 0.0525573960717558\n",
      "epoch: 32, iteration: 70000, loss: 0.03111953727030665\n",
      "epoch: 33, iteration: 0, loss: 0.04835296962453358\n",
      "epoch: 33, iteration: 10000, loss: 0.0505031139895875\n",
      "epoch: 33, iteration: 20000, loss: 0.03917678461817882\n",
      "epoch: 33, iteration: 30000, loss: 0.02457191941431797\n",
      "epoch: 33, iteration: 40000, loss: 0.06831913407174471\n",
      "epoch: 33, iteration: 50000, loss: 0.056085469092217524\n",
      "epoch: 33, iteration: 60000, loss: 0.03468200619808319\n",
      "epoch: 33, iteration: 70000, loss: 0.05895991659632381\n",
      "epoch: 34, iteration: 0, loss: 0.04124224097715624\n",
      "epoch: 34, iteration: 10000, loss: 0.04022963319167149\n",
      "epoch: 34, iteration: 20000, loss: 0.03989650142794311\n",
      "epoch: 34, iteration: 30000, loss: 0.07391749249361161\n",
      "epoch: 34, iteration: 40000, loss: 0.029351881702755406\n",
      "epoch: 34, iteration: 50000, loss: 0.044221992294456614\n",
      "epoch: 34, iteration: 60000, loss: 0.054227434673088715\n",
      "epoch: 34, iteration: 70000, loss: 0.025506873307145482\n",
      "epoch: 35, iteration: 0, loss: 0.042493033398435485\n",
      "epoch: 35, iteration: 10000, loss: 0.07733778582025799\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-f43a65ad1a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "    \n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        loss = F.mse_loss(net(x), y)\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "    \n",
    "        if i % 10000 == 0:\n",
    "            print(f'epoch: {epoch}, iteration: {i}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.stack([\n",
    "    torch.linspace(90e6, 110e6, 1024),\n",
    "    U*torch.ones(1024)\n",
    "], 1).double().unsqueeze(0)\n",
    "\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6509,  0.6509,  0.6509,  ...,  0.6509,  0.6509,  0.6509], dtype=torch.float64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6495000000000004"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1432942897081375"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lin1): Linear(in_features=2, out_features=64, bias=True)\n",
      "  (lin2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
